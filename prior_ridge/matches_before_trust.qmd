---
title: "matches_before_trust"
format: html
---

```{r}
# Question: 
# Do want to use each event's optimal lamba? 
# Or the average/median lambda across that week or year?
# Or some random lambda to simulate the varying levels of trust (iffy on the logic behind this)
# something else?
# Running on the first assumption in this code

# Main Ideas:
# Use TBA schedules to get a list of teams per match per event
# Combine all the TBA schedules for one team into one long (but easy) statbotics call
# Use scoutR's team_matches_sb(team = x, event = "key") and select the matches we're interested in
# Use that to calculate EPA's MSE???
# Pull that event's optimal lambda from the lambda_opts dataframe
# Run pridge_lambda_cv with that event's start EPAs and limited by match size
#   start EPAs probably pulled through scoutR event_sb
#   this is going to take so much computing power...
#   MSE based on LOOCV on matches before n, or do we want to include the results from later matches?
# make pretty graff

library(tidyverse)
library(ggplot2)
library(scoutR)

lambda_opts <- read.csv("pridge_pct_improvement15-25.csv") |> select(key, lambda_opt)
lambda_opts <- lambda_opts |> filter(is.na(lambda_opt) == FALSE)

data <- lambda_opts |>
    rowwise() |>
    mutate(
        teams = list(sort(sapply(event_teams(key)$team_number, as.integer)))
    )

team <- sort(unique(unlist(data$teams)))
team_epas <- data.frame(team)

temp <- matrix(ncol = length(team), nrow = length(data[[1]]), data = 0)
temp <- as.data.frame(temp)
#rownames(temp) <- team
names(temp) <- team

get_epa_progression <- function(team_key, event_key){
    tm <- team_matches_sb(team = team_key, event = event_key, elim = FALSE)
    result <- map(tm, ~{
        data.frame(
            team = .x$team, 
            match = .x$match, 
            time = .x$time, 
            pre_epa = .x$epa$total_points, 
            post_epa = .x$epa$post
        )}) |>
        list_rbind() |>
        arrange(time)
    return(result)
}

temp <- cbind(data, temp)

for (i in 1:nrow(temp)) {
    for (j in 1:length(temp$teams[[i]])) {
        temp[i, as.character(unlist(temp$teams[i])[j])] = 1
    }
}

temp <- select(temp, !c(lambda_opt, teams))

team_epas <- data.frame(team)

for (i in 1:nrow(temp)) {
    for (j in 1:ncol(temp)) {
        if (temp[[i]][j] == 1) {
            get_epa_regression(colnames(temp)[j+1], temp$key[i])
        }
    }
}

#lowkey going to sleep rn, will send out an update tmrw by 10am with progress (so maybe people [as in margaret] at the meeting can work on it)
```

```{r}
library(tidyverse)
library(scoutR)
get_epa_progression <- function(team_key, event_key){
        tm <- team_matches_sb(team = team_key, event = event_key, elim = FALSE)
        result <- map(tm, ~{
            data.frame(
                team = .x$team, 
                match = as.integer(gsub(paste0(event_key, "_qm"), "", .x$match)),
                alliance = .x$alliance,
                time = .x$time, 
                pre_epa = .x$epa$total_points, 
                post_epa = .x$epa$post
            )}) |>
            list_rbind() |>
            arrange(time)
        return(result)
    }
#event_key = "2025vagle"
event_epa_mse <- function(event_key) {
    team <- sort(as.integer(event_teams(event_key)$team_number))
    data <- lapply(team, get_epa_progression, event = event_key) |>
        purrr::reduce(rbind) |>
        group_by(match, alliance) |>
        summarise(
            pred_score = sum(pre_epa)
        )
    
    real_scores <- event_matches(event_key, match_type = "quals")[, c("blue_score", "red_score")] |>
        pivot_longer(
            cols = c("blue_score", "red_score"),
            names_to = "alliance",
            values_to = "scores"
        ) |>
        select(scores)
    data <- cbind(data, real_scores) 
    data <- data |>
        rowwise() |>
        mutate(
            residuals = pred_score - scores,
        )
    
    mean(data$residuals^2)
}
event_epa_mse("2025vagle")
# ~0.147 tba calls per second
```

```{r}
library(tidyverse)
library(scoutR)
library(purrr)

get_epa_progression <- function(team_key){
    tm1 <- team_matches_sb(team = team_key, elim = FALSE, year = 2015)
    tm2 <- team_matches_sb(team = team_key, elim = FALSE, year = 2016)
    tm3 <- team_matches_sb(team = team_key, elim = FALSE, year = 2017)
    tm4 <- team_matches_sb(team = team_key, elim = FALSE, year = 2018)
    tm5 <- team_matches_sb(team = team_key, elim = FALSE, year = 2019)
    tm6 <- team_matches_sb(team = team_key, elim = FALSE, year = 2022)
    tm7 <- team_matches_sb(team = team_key, elim = FALSE, year = 2023)
    tm8 <- team_matches_sb(team = team_key, elim = FALSE, year = 2024)
    tm9 <- team_matches_sb(team = team_key, elim = FALSE, year = 2025)
    tm <- rbind(tm1, tm2, tm3, tm4, tm5, tm6, tm7, tm8, tm9)
    #tm <- team_matches_sb(team = team_key, elim = FALSE)
    
    result <- map(tm, ~{
        data.frame(
            team = .x$team, 
            year = .x$year,
            event = .x$event,
            match = as.integer(sub(".*_qm", "", .x$match)),
            alliance = .x$alliance,
            time = .x$time, 
            week = .x$week,
            pre_epa = .x$epa$total_points
            #pre_epa = pluck(.x, "epa", "total_points", .default = NA)
        )}) |>
        list_rbind()
    return(result)
}

#year <- 2025
lambda_opt <- read.csv("pridge_pct_improvement15-25.csv") |>
    filter(!is.na(lambda_opt)) 
data <- lambda_opt#[grepl(as.character(year), lambda_opt$key), ] 
unique_teams <- data |>
    rowwise() |>
    mutate(
        teams = list(sort(sapply(event_teams(key)$team_number, as.integer)))
    ) # ~three minutes

unique_teams2 <- sort(as.integer(unique(unlist(unique_teams$teams))))

team_info <- lapply(unique_teams2, get_epa_progression) |> #35 mins
    reduce(rbind) #|>
write.csv(team_info, "all_epas_for_all_teams.csv", row.names = FALSE)

    arrange(event, match, alliance) |>
    group_by(event, match, alliance) |>
    summarise(
        pred_score = sum(pre_epa)
    )

real_scores <- map_dfr(
    sort(data$key), 
    ~event_matches(event_key = .x, match_type = "quals")) |>
    select(blue_score, red_score, key) |>
    pivot_longer(
        cols = c("blue_score", "red_score"),
        names_to = "alliance",
        values_to = "scores"
    )
real_scores <- real_scores |>
    rowwise() |>
    mutate(
        event = sub(paste0("_qm", ".*"), "", key),
        match = as.integer(sub(".*_qm", "", key))
    ) |>
    arrange(event, match, alliance)

```

```{r}
library(tidyverse)
library(scoutR)

team_info <- read.csv("data/all_epas_for_all_teams.csv") |>
    arrange(event, match, alliance) |>
    filter(event %in% lambda_opt$key) |>
    unique()
lambda_opt <- read.csv("data/pdridge_pct_improvement15-25.csv") |>
    filter(!is.na(lambda_opt)) 

data <- team_info |>
    group_by(event, match, alliance) |>
    summarise(
        pred_score = sum(pre_epa),
        num_teams = n()
    ) |>
    ungroup() |>
    rowwise() |>
    mutate(
        event_key = paste0(event, "_qm", match)
    ) |>
    filter(event_key %in% real_scores$key)

data$score <- real_scores$scores
data <- data |>
    mutate(
        residual = pred_score - score
    ) |>
    group_by(event) |>
    summarise(
        EPA_mse = mean(residual^2)
    )
```

```{r}
fit_event_pridge <- function(
        event_key, grid = seq(0, 20, length.out = 1000), n_cores = NULL
){
    matches <- event_matches(event_key, match_type = "qual")

    design <- as.matrix(lineup_design_matrix(matches))
    response <- c(matches$blue_score, matches$red_score)

    sb_data <- team_events_sb(event = event_key)
    epas <- sapply(sb_data, function(te){te$epa$stats$start})
    names(epas) <- sapply(sb_data, function(te){te$team})

    mses <- pridge_lambda_cv(design, response, epas, grid, n_cores = n_cores, plot_mses = FALSE)
    return(mses)
}

lambda_opt <- read.csv("data/pridge_pct_improvement15-25.csv") |>
    filter(!is.na(lambda_opt))
lambda_opt <- lambda_opt |>
    rowwise() |>
    mutate(
        pridge_mse = min(fit_event_pridge(key))
    )

lambda_opt <- lambda_opt |>
    arrange(key)

data$key <- lambda_opt$key
data$pct_imp <- lambda_opt$pct_imp
data$lambda_opt <- lambda_opt$lambda_opt
data$pridge_mse <- lambda_opt$pridge_mse

data$rows <- 1:length(data$key)

data2 <- data |> filter(substring(key))

ggplot(data, aes(x = rows)) + 
    geom_line(aes(y = EPA_mse), color = "#a9000a") + 
    geom_line(aes(y = pridge_mse), color = "blue") +
    scale_y_log10() +
    theme_bw()
```

```{r}
library(tidyverse)
library(ggplot2)
library(scoutR)
library(foreach)
library(doParallel)

pridge_lambda_cv <- function(
        design, response, priors, lambda, plot_mses = FALSE, n_cores = NULL
){
    design <- as.matrix(design)
    
    # Leave one core free by default
    if (is.null(n_cores)) {
        n_cores <- max(1, parallel::detectCores() - 1)
    }
    cl <- parallel::makeCluster(n_cores)
    doParallel::registerDoParallel(cl)
    
    mses <- tryCatch({
        foreach::foreach(
            lambda = grid, .export = c("pridge_loocv", "prior_ridge"), 
            .combine = 'c', .packages = 'scoutR'
        ) %dopar% {
            pridge_loocv(design, response, lambda, priors)
        }
    }, finally = {
        # Always stop the cluster to free up resources
        parallel::stopCluster(cl)
    })
    return(mses)
}


pridge_loocv <- function(X, y, lambda, beta_0, mse = TRUE){
    errors <- rep(NA, length(y))
    for (i in seq_along(y)){
        X_train <- X[-i, ]
        y_train <- y[-i]
        X_test <- X[i, ]
        y_test <- y[i]
        # train on the training data
        coefs <- prior_ridge(X_train, y_train, lambda, beta_0)
        # make predictions using test data and compute error
        pred <- X_test %*% coefs
        # use drop() to ensure the error is a vector, not a matrix
        errors[i] <- drop(pred - y_test)
    }
    if(mse) return(mean(errors ^ 2))
    return(errors)
}

prior_ridge <- function(X, y, lambda, beta_0) {
    stopifnot("lambda must be a single value" = {length(lambda) == 1})
    stopifnot("coefficients in beta_0 must match ncol(X)" =
                  {length(beta_0) == ncol(X)})
    p <- ncol(X)
    lambda <- diag(lambda, p)
    solve(crossprod(X) + lambda, crossprod(X, y) + lambda %*% beta_0)[, 1]
}

per_match_comparison <- function(team_info, event_key, matches_interested) {
    team_info <- filter(team_info, event == event_key) |> distinct()
    
    data <- team_info |>
        group_by(event, match, alliance) |>
        summarise(
            pred_score = sum(pre_epa),
            num_teams = n()
        ) |>
        ungroup() |>
        rowwise() |>
        mutate(
            event_key = paste0(event, "_qm", match)
        )
    
    matches <- event_matches(event_key, match_type = "qual") # Set-up pridge_lambda_cv
    design <- as.matrix(lineup_design_matrix(matches))
    response <- c(matches$blue_score, matches$red_score)
    sb_data <- team_events_sb(event = event_key)
    epas <- sapply(sb_data, function(te){te$epa$stats$start})
    names(epas) <- sapply(sb_data, function(te){te$team})
    grid <- seq(1, 20, length.out = 1000) # why does it break if we start at 0?
    
    pridge_mses <- sapply(matches_interested, function(i){
        red_indices_start <- length(design[ ,1]) / 2
        design_temp <- rbind(
            design[1:i, ], design[red_indices_start:(red_indices_start + i), ])
        response_temp <- c(
            response[1:i], response[red_indices_start:(red_indices_start + i)]
        )
        mses <- pridge_lambda_cv(design_temp, response_temp, epas, grid)
        min(mses)
    })
    
    real_scores <- event_matches(event_key, match_type = "quals")[, c("blue_score", "red_score")] |>
            pivot_longer(
                cols = c("blue_score", "red_score"),
                names_to = "alliance",
                values_to = "scores"
            ) |>
            select(scores)
    
    data$score <- real_scores$scores
    data <- data |>
        mutate(
            epa_residual_squared = (pred_score - score)^2
        )
    
    epa_mse <- sapply(matches_interested, function(i) {
        mean(data$epa_residual_squared[1:i])
        })
    
    opr_mse <- sapply(matches_interested, function(i){
        red_indices_start <- length(design[ ,1]) / 2
        design_temp <- rbind(
            design[1:i, ], design[red_indices_start:(red_indices_start + i), ])
        response_temp <- c(
            response[1:i], response[red_indices_start:(red_indices_start + i)]
        )
        
        design_temp <- cbind(as.data.frame(design_temp), response_temp)
        
        mses <- mean((lm(
            response_temp ~ 0, data = design_temp, 
            weights = rep(1, nrow(design_temp)))$residuals) ** 2)
    })
    
    comparison <- data.frame(pridge_mses, epa_mse) |>
        pivot_longer(
            cols = c("pridge_mses", "epa_mse"),
            names_to = "type", 
            values_to = "values"
        )
    
    comparison$matches_interested <- 
        sort(rep(matches_interested, length(unique(comparison$type))))
    
    ggplot(comparison, aes(x = matches_interested, y = values, color = type)) +
        geom_line() + 
        theme_bw()
}

event_key <- "2025mdsev"
team_info <- read.csv("data/all_epas_for_all_teams.csv")    
matches_interested <- 5:30

a <- per_match_comparison(team_info, event_key, matches_interested)
a
```
